{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbqHfvwZHnk4"
   },
   "outputs": [],
   "source": [
    "# Instalamos KERAS\n",
    "!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ODuccLWZZxJE",
    "outputId": "916db53b-4858-4569-90ea-58b3b645d762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dataset_ger'...\n",
      "remote: Enumerating objects: 51927, done.\u001b[K\n",
      "remote: Counting objects: 100% (51927/51927), done.\u001b[K\n",
      "remote: Compressing objects: 100% (51754/51754), done.\u001b[K\n",
      "remote: Total 51927 (delta 172), reused 51927 (delta 172), pack-reused 0\n",
      "Receiving objects: 100% (51927/51927), 341.66 MiB | 34.23 MiB/s, done.\n",
      "Resolving deltas: 100% (172/172), done.\n",
      "Checking out files: 100% (51886/51886), done.\n"
     ]
    }
   ],
   "source": [
    "# Descargamos el dataset\n",
    "!git clone https://github.com/agonzalezhidalgo/dataset_ger.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uDKgXudXaYJF",
    "outputId": "550a692a-30ea-4d1d-9ef0-c96f23488ab5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-image.org/docs/stable/api/api.html\n",
    "import skimage\n",
    "\n",
    "# https://docs.python.org/3/library/csv.html\n",
    "import csv\n",
    "\n",
    "# https://matplotlib.org/api/index.html\n",
    "import matplotlib\n",
    "\n",
    "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://docs.python.org/3/library/os.html\n",
    "import os\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy/reference/\n",
    "import numpy as np\n",
    "\n",
    "# https://keras.io/models/model/\n",
    "import keras\n",
    "\n",
    "from keras import models\n",
    "\n",
    "# Core Layers: https://keras.io/layers/core/\n",
    "# Convolution Layers: https://keras.io/layers/convolutional/\n",
    "from keras import layers\n",
    "\n",
    "# https://keras.io/preprocessing/image/\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# https://keras.io/callbacks/\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16_v-R69B9XO"
   },
   "source": [
    "Celda con funciones generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jP7IhbsUOsc"
   },
   "outputs": [],
   "source": [
    "# Devuelve las imagenes y etiquetas de una carpeta especifíca\n",
    "def __read_images_labels_from_dir(directory, images, labels, shape, as_gray, get_label_from_dir):\n",
    "    \n",
    "    #Buscamos fotos en el directorio\n",
    "    for f in os.listdir(directory):\n",
    "        # Cargamos archivos con extension .ppm \n",
    "        # Obviamos el color y lo cargamos como escala de grises y normalizamos el tamaño\n",
    "        if f.endswith(\".ppm\"):\n",
    "            image = load_image(os.path.join(directory, f), shape, as_gray)\n",
    "            images.append(image)\n",
    "            if get_label_from_dir:\n",
    "                labels.append(int(os.path.basename(directory)))\n",
    "    \n",
    "    return images, labels\n",
    "  \n",
    "# Obtenemos el índice inicial y final de una label específica\n",
    "# - label: índice de la label que se quiere buscar.\n",
    "# - source: lista de la relación de etiquetas.\n",
    "\n",
    "def __get_start_end(label, source):\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    try:        \n",
    "        start = source.index(label)\n",
    "        end = start + source.count(label)\n",
    "\n",
    "    except:\n",
    "        print(\"label doesn't exist\")\n",
    "\n",
    "    return start, end\n",
    "  \n",
    "# Devuelve una colección de directorios de la ruta\n",
    "def __get_directories(data_dir):\n",
    "    \n",
    "    directories = []\n",
    "    \n",
    "    if os.path.exists(data_dir):\n",
    "        \n",
    "        #Buscamos todos los directorios de la ruta\n",
    "        for d in os.listdir(data_dir):\n",
    "            if os.path.isdir(os.path.join(data_dir, d)):\n",
    "                directories.append(d)\n",
    "                \n",
    "    else:\n",
    "        print(\"path doesn't exists\")\n",
    "    return directories\n",
    "  \n",
    "# Devuelve una colección con las imágenes y los labels de la ruta\n",
    "# -datadir: path donde se encuentran la colección de imágenes.\n",
    "# -shape: Dimensiones con las que se cargarán las imágenes.\n",
    "# -as_gray: Indica si la imagen se cargará en escala de grises.\n",
    "# -get_label_from_dir: (defecto True) específica si la categoría se lee del propio directorio\n",
    "def readDataset(data_dir, shape, as_gray, get_label_from_dir = True):\n",
    "    images = []\n",
    "    labels = []\n",
    "    directories = __get_directories(data_dir)\n",
    "    \n",
    "    images, labels = __read_images_labels_from_dir(data_dir, images, labels, shape, as_gray, get_label_from_dir)\n",
    "    \n",
    "    for d in directories:\n",
    "                \n",
    "        #Buscamos fotos en el directorio\n",
    "        images_dir = os.path.join(data_dir, d)\n",
    "        images, labels = __read_images_labels_from_dir(images_dir, images, labels, shape, as_gray, get_label_from_dir)\n",
    "       \n",
    "    return images, labels\n",
    "  \n",
    "# Devuelve una imagen\n",
    "# - path: ruta de la imagen.\n",
    "# - size: dimensión con la que se cargará la imagen.\n",
    "# - as_gray: True para cargar la imagen en escala de grises.\n",
    "\n",
    "def load_image(path, size, as_gray):\n",
    "    aux = skimage.data.imread(path, as_gray = as_gray)\n",
    "    return skimage.transform.resize(aux, size, mode='constant')\n",
    "  \n",
    "# Devuelve una lista con los datos del fichero csv.\n",
    "# - path: ruta hasta el fichero csv.\n",
    "# - delimeter: Carácter delimitador de campos\n",
    "\n",
    "def read_csv(path, delimiter):\n",
    "    file = open(path)\n",
    "    title_csv = csv.reader(file, delimiter = delimiter)\n",
    "    return list(title_csv)\n",
    "  \n",
    "# Imprime los tamaños de las colecciones\n",
    "# - images: lista de imágenes precargadas.\n",
    "# - labels: relación de las imágenes con las categorías a las que pertenecen.\n",
    "# - np_images: np.array con las imágenes precargadas.\n",
    "# - np_labels: np.array con las categorías precargadas.\n",
    "# - environment: string identificativo del entorno.\n",
    "\n",
    "def print_size_dataset(images, labels, np_images, np_labels, environment):\n",
    "    print(\"Total images (\" + environment + \"): \", len(images))\n",
    "    print(\"Total labels (\" + environment + \"): \", len(set(labels)))\n",
    "    print(\"Images shape: \", np_images.shape)\n",
    "    print(\"Labels shape: \", np_labels.shape)\n",
    "    \n",
    "# Imprime una matriz 32x32 con los diferentes tipos de señales que\n",
    "# se van a clasificar. Muestra la primera imagen de cada categoría.\n",
    "# - images: lista de imágenes precargadas.\n",
    "# - labels: relación de las imágenes con las categorías a las que pertenecen.\n",
    "# - titles: lista con los nombres de las categorías.\n",
    "\n",
    "def print_summary_dataset(images, labels, titles):\n",
    "    \n",
    "    #Quitamos los repetidos a los labels\n",
    "    unique_labels = set(labels)\n",
    "    \n",
    "    plt.figure(figsize=(32, 32))\n",
    "    i = 1\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        \n",
    "        #Obtenemos la primera imagén de cada label\n",
    "        image = images[labels.index(label)]\n",
    "        plt.subplot(8, 8, i)\n",
    "        plt.axis('off')\n",
    "        plt.title(titles[i-1][1])\n",
    "        i += 1\n",
    "        _ = plt.imshow(image)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "# Imprime todas las imágenes de una label especifica\n",
    "# - label: índice de la label que se quiere buscar.\n",
    "# - images: lista de imágenes precargadas.\n",
    "# - source: lista de la relación de etiquetas.\n",
    "# - titles: lista con las diferentes categorías de labels.\n",
    "\n",
    "def print_signals(label, images, source, titles):\n",
    "    \n",
    "    start, end = __get_start_end(label, source)\n",
    "    \n",
    "    if start < end:\n",
    "        rows = (end - start) / 8\n",
    "\n",
    "        print(\"Signal: \", titles[label][1])\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        i = 1\n",
    "\n",
    "        for image in images[start:end]:\n",
    "            plt.subplot(rows + 1, 8, i)\n",
    "            plt.axis('off')\n",
    "            i += 1\n",
    "            plt.imshow(image)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "# Imprime los atributos de las imágenes de una label especifica.\n",
    "# - label: índice de la label que se quiere buscar.\n",
    "# - images: lista de imágenes precargadas.\n",
    "# - source: lista de la relación de etiquetas.\n",
    "# - titles: lista con las diferentes categorías de labels.\n",
    "\n",
    "def print_signals_attributes(label, images, source, titles):\n",
    "    \n",
    "    start, end = __get_start_end(label, source)\n",
    "    \n",
    "    if start < end:\n",
    "        print(\"Signal: \", titles[label][1])\n",
    "        for image in images[start:end]:\n",
    "            print(\"shape: \", image.shape, \"\\tmin:\", image.min(), \"\\tmax: \", image.max())\n",
    "            \n",
    "# Devuelve una lista con las categorías de las imágenes de prueba leídas del fichero csv.\n",
    "# - csv: fichero csv\n",
    "# - class_column: número de columna que contiene las clases.\n",
    "# - first_is_header: Indica si la primera fila es una cabecerá.\n",
    "\n",
    "def get_class_id_array(csv, class_column, first_is_header = True):\n",
    "    labels = []\n",
    "    for row in csv:\n",
    "        if not first_is_header:\n",
    "            labels.append(int(row[class_column]))\n",
    "        else:\n",
    "            first_is_header = False\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "3WZtFcFKbB6-",
    "outputId": "b5e62469-abb2-431f-99e7-5f9ce55b2647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13015287545796612542\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15639097512752874655\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8268828737526546441\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14892338381\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14513458241014608062\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Mostramos información de CPU & GPU\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MpZFFb5OZ3Dg",
    "outputId": "dc866c9a-93bc-4b4f-e9e1-40cf1bdb7657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de las imágenes de entrada:  (32, 32)\n",
      "Vectorizando la entrada, sería de un tamaño:  1024\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el directorio actual como trabajo.\n",
    "ROOT_PATH = os.getcwd()\n",
    "\n",
    "# Establecemos la dimensión de las imágenes.\n",
    "IMG_SHAPE = (32, 32)\n",
    "print(\"Tamaño de las imágenes de entrada: \", IMG_SHAPE)\n",
    "IMG_SHAPE_LEN = IMG_SHAPE[0] * IMG_SHAPE[1]\n",
    "print(\"Vectorizando la entrada, sería de un tamaño: \", IMG_SHAPE_LEN)\n",
    "\n",
    "# Obtenemos los paths de trabajo\n",
    "labels_path = os.path.join(ROOT_PATH, \"dataset_ger/labels.csv\")\n",
    "train_path = os.path.join(ROOT_PATH, \"dataset_ger/train/Images\")\n",
    "test_info_path = os.path.join(ROOT_PATH, \"dataset_ger/test/GT-final_test.csv\")\n",
    "test_path = os.path.join(ROOT_PATH, \"dataset_ger/test/Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "n_55nevcUQHR",
    "outputId": "994d1a9e-7d15-40f5-c260-72e680d81392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images (train):  39209\n",
      "Total labels (train):  43\n",
      "Images shape:  (39209, 32, 32, 3)\n",
      "Labels shape:  (39209,)\n",
      "Titles total:  43\n"
     ]
    }
   ],
   "source": [
    "# Cargamos las imágenes de entrenamiento.\n",
    "images_train, labels_train = readDataset(train_path, IMG_SHAPE, False)\n",
    "\n",
    "# Convertimos las listas a array numpy de float32\n",
    "np_images_train = np.asarray(images_train, dtype = np.float32)\n",
    "np_labels_train = np.asarray(labels_train, dtype = np.int8)\n",
    "\n",
    "# Recuperamos los nombres de las categorias. Los diferentes tipo de señales\n",
    "# que se van a clasificar.\n",
    "titles = read_csv(labels_path, \",\")\n",
    "\n",
    "# Se imprime información de los datos cargados.\n",
    "print_size_dataset(images_train, labels_train, np_images_train, np_labels_train, \"train\")\n",
    "print(\"Titles total: \", len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "9J8iZFpgC7tH",
    "outputId": "7b9c261d-ef83-40c3-c135-bceb759892be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images (test):  12630\n",
      "Total labels (test):  43\n",
      "Images shape:  (12630, 32, 32, 3)\n",
      "Labels shape:  (12630,)\n"
     ]
    }
   ],
   "source": [
    "# Cargamos las imágenes de entrenamiento.\n",
    "images_test, labels_test = readDataset(test_path, IMG_SHAPE, False, False)\n",
    "\n",
    "test_info  = read_csv(test_info_path, \";\")\n",
    "labels_test = get_class_id_array(test_info, 7)\n",
    "\n",
    "# Convertimos las listas a array numpy de float32\n",
    "np_images_test = np.asarray(images_test, dtype = np.float32)\n",
    "np_labels_test = np.asarray(labels_test, dtype = np.int8)\n",
    "\n",
    "# Se imprime información de los datos cargados.\n",
    "print_size_dataset(images_test, labels_test, np_images_test, np_labels_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2W2tKUgvUukC",
    "outputId": "ba8b75c8-f5b9-4304-a39b-49ef9308793d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo primera imagen de manera categórica:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Convertimos las labels de manera categórica\n",
    "labels_categorical_train = keras.utils.to_categorical(np_labels_train)\n",
    "labels_categorical_test = keras.utils.to_categorical(np_labels_test)\n",
    "\n",
    "print(\"Ejemplo primera imagen de manera categórica: \", labels_categorical_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhL5rFelZfLv"
   },
   "outputs": [],
   "source": [
    "def get_keras_model():\n",
    "    # IMPLEMENTACIÓN RED NEURONAL\n",
    "    # En Keras la envoltura para cualquier red neuronal se crea con la clase Sequential\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (5, 5),\n",
    "                            activation='selu', input_shape=(IMG_SHAPE[0], IMG_SHAPE[1], 3)))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (5, 5), activation='selu'))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(len(set(labels_train)), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "colab_type": "code",
    "id": "r8Cucwmicr1K",
    "outputId": "f2752a0a-23c3-4f7a-cabc-ce7a9e230b3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0616 06:51:34.466064 140022545856384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0616 06:51:34.475628 140022545856384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0616 06:51:34.487811 140022545856384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0616 06:51:34.516356 140022545856384 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3217: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0616 06:51:34.521982 140022545856384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0616 06:51:34.525038 140022545856384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0616 06:51:34.535833 140022545856384 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0616 06:51:34.623186 140022545856384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0616 06:51:34.643078 140022545856384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 43)                11051     \n",
      "=================================================================\n",
      "Total params: 64,747\n",
      "Trainable params: 64,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "12630/12630 [==============================] - 1s 66us/step\n",
      "Test loss: 15.111297430580604\n",
      "Test accuracy: 0.037212984958812534\n"
     ]
    }
   ],
   "source": [
    "model = get_keras_model()\n",
    "\n",
    "# Muestra la arquitectura de nuestra red neuronal\n",
    "model.summary()\n",
    "\n",
    "# Configurando el modelo de aprendijaze:\n",
    "#  · loss, función para evaluar el grado de error entre salidas calculadas\n",
    "#  · optimizador, función para calcular los pesos de los parámetros a partir de los datos de entrada\n",
    "#  · metricas, para monitorizar el proceso de aprendizaje de la red.\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"rmsprop\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "# - batch_size, indica el número de datos que se usan en cada actualización.\n",
    "# - epochs, indica el número de veces que se usan todos los datos del proceso.\n",
    "#model.fit(np_images_train, labels_categorical_train, batch_size=32, epochs=20)\n",
    "model.fit(np_images_train, labels_categorical_train,\n",
    "          batch_size = 128,\n",
    "          epochs = 25,\n",
    "          verbose = 0,\n",
    "          callbacks=[ModelCheckpoint('model_32_32_gpu_ger.h5', save_best_only = False)])\n",
    "\n",
    "# Evaluación del modelo\n",
    "test_loss, test_acc = model.evaluate(np_images_test, labels_categorical_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgI3rrdScsRg"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             featurewise_std_normalization=False, \n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10.,)\n",
    "\n",
    "datagen.fit(np_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "QftMYJbmcz3d",
    "outputId": "d19f41ae-16b4-43e9-ced1-12e6d081a55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 568s - loss: 0.4204 - acc: 0.8864\n",
      "Epoch 2/25\n",
      " - 566s - loss: 0.2416 - acc: 0.9400\n",
      "Epoch 3/25\n",
      " - 566s - loss: 0.2065 - acc: 0.9493\n",
      "Epoch 4/25\n",
      " - 572s - loss: 0.1893 - acc: 0.9536\n",
      "Epoch 5/25\n",
      " - 569s - loss: 0.1794 - acc: 0.9564\n",
      "Epoch 6/25\n",
      " - 568s - loss: 0.1716 - acc: 0.9581\n",
      "Epoch 7/25\n",
      " - 567s - loss: 0.1696 - acc: 0.9594\n",
      "Epoch 8/25\n",
      " - 569s - loss: 0.1676 - acc: 0.9606\n",
      "Epoch 9/25\n",
      " - 570s - loss: 0.1643 - acc: 0.9617\n",
      "Epoch 10/25\n",
      " - 567s - loss: 0.1632 - acc: 0.9621\n",
      "Epoch 11/25\n",
      " - 570s - loss: 0.1632 - acc: 0.9622\n",
      "Epoch 12/25\n",
      " - 569s - loss: 0.1645 - acc: 0.9624\n",
      "Epoch 13/25\n",
      " - 569s - loss: 0.1647 - acc: 0.9626\n",
      "Epoch 14/25\n",
      " - 575s - loss: 0.1636 - acc: 0.9628\n",
      "Epoch 15/25\n",
      " - 572s - loss: 0.1667 - acc: 0.9630\n",
      "Epoch 16/25\n",
      " - 579s - loss: 0.1642 - acc: 0.9631\n",
      "Epoch 17/25\n",
      " - 587s - loss: 0.1651 - acc: 0.9634\n",
      "Epoch 18/25\n",
      " - 579s - loss: 0.1652 - acc: 0.9633\n",
      "Epoch 19/25\n",
      " - 579s - loss: 0.1671 - acc: 0.9635\n",
      "Epoch 20/25\n",
      " - 574s - loss: 0.1689 - acc: 0.9635\n",
      "Epoch 21/25\n",
      " - 575s - loss: 0.1696 - acc: 0.9634\n",
      "Epoch 22/25\n",
      " - 578s - loss: 0.1695 - acc: 0.9636\n",
      "Epoch 23/25\n",
      " - 575s - loss: 0.1692 - acc: 0.9636\n",
      "Epoch 24/25\n",
      " - 577s - loss: 0.1686 - acc: 0.9637\n",
      "Epoch 25/25\n",
      " - 576s - loss: 0.1703 - acc: 0.9634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f592c17edd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = get_keras_model()\n",
    "\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"rmsprop\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_2.fit_generator(datagen.flow(np_images_train, labels_categorical_train, batch_size=32),\n",
    "                      steps_per_epoch = np_images_train.shape[0],\n",
    "                      epochs = 25,\n",
    "                      verbose = 2,\n",
    "                      callbacks=[ModelCheckpoint('model_data_aug_32_32_gpu_ger.h5',save_best_only = False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "nej9Qatoc0Gd",
    "outputId": "241526ed-15bf-4500-98b9-9b95d240c00a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630/12630 [==============================] - 1s 78us/step\n",
      "Test loss: 15.273197984280136\n",
      "Test accuracy: 0.0373713380862868\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "test_loss, test_acc = model_2.evaluate(np_images_test, labels_categorical_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "traffic_red_convolucional_gpu_ger",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
