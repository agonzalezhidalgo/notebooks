{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_red_convolucional_gpu_ger",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbqHfvwZHnk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instalamos KERAS\n",
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODuccLWZZxJE",
        "colab_type": "code",
        "outputId": "575d09ae-5dae-4dc6-edc2-12b37d27c8c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Descargamos el dataset\n",
        "!git clone https://github.com/agonzalezhidalgo/dataset_ger.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dataset_ger'...\n",
            "remote: Enumerating objects: 51927, done.\u001b[K\n",
            "remote: Counting objects: 100% (51927/51927), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51754/51754), done.\u001b[K\n",
            "remote: Total 51927 (delta 172), reused 51927 (delta 172), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (51927/51927), 341.66 MiB | 32.15 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "Checking out files: 100% (51886/51886), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDKgXudXaYJF",
        "colab_type": "code",
        "outputId": "c4f02a71-eed9-4cf9-dcaa-37b489da6dba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# http://scikit-image.org/docs/stable/api/api.html\n",
        "import skimage\n",
        "\n",
        "# https://docs.python.org/3/library/csv.html\n",
        "import csv\n",
        "\n",
        "# https://matplotlib.org/api/index.html\n",
        "import matplotlib\n",
        "\n",
        "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# https://docs.python.org/3/library/os.html\n",
        "import os\n",
        "\n",
        "# https://docs.scipy.org/doc/numpy/reference/\n",
        "import numpy as np\n",
        "\n",
        "# https://keras.io/models/model/\n",
        "import keras\n",
        "\n",
        "from keras import models\n",
        "\n",
        "# Core Layers: https://keras.io/layers/core/\n",
        "# Convolution Layers: https://keras.io/layers/convolutional/\n",
        "from keras import layers\n",
        "\n",
        "# https://keras.io/preprocessing/image/\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# https://keras.io/callbacks/\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16_v-R69B9XO",
        "colab_type": "text"
      },
      "source": [
        "Celda con funciones generales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jP7IhbsUOsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Devuelve las imagenes y etiquetas de una carpeta especifíca\n",
        "def __read_images_labels_from_dir(directory, images, labels, shape, as_gray, get_label_from_dir):\n",
        "    \n",
        "    #Buscamos fotos en el directorio\n",
        "    for f in os.listdir(directory):\n",
        "        # Cargamos archivos con extension .ppm \n",
        "        # Obviamos el color y lo cargamos como escala de grises y normalizamos el tamaño\n",
        "        if f.endswith(\".ppm\"):\n",
        "            image = load_image(os.path.join(directory, f), shape, as_gray)\n",
        "            images.append(image)\n",
        "            if get_label_from_dir:\n",
        "                labels.append(int(os.path.basename(directory)))\n",
        "    \n",
        "    return images, labels\n",
        "  \n",
        "# Obtenemos el índice inicial y final de una label específica\n",
        "# - label: índice de la label que se quiere buscar.\n",
        "# - source: lista de la relación de etiquetas.\n",
        "\n",
        "def __get_start_end(label, source):\n",
        "\n",
        "    start = 0\n",
        "    end = 0\n",
        "    \n",
        "    try:        \n",
        "        start = source.index(label)\n",
        "        end = start + source.count(label)\n",
        "\n",
        "    except:\n",
        "        print(\"label doesn't exist\")\n",
        "\n",
        "    return start, end\n",
        "  \n",
        "# Devuelve una colección de directorios de la ruta\n",
        "def __get_directories(data_dir):\n",
        "    \n",
        "    directories = []\n",
        "    \n",
        "    if os.path.exists(data_dir):\n",
        "        \n",
        "        #Buscamos todos los directorios de la ruta\n",
        "        for d in os.listdir(data_dir):\n",
        "            if os.path.isdir(os.path.join(data_dir, d)):\n",
        "                directories.append(d)\n",
        "                \n",
        "    else:\n",
        "        print(\"path doesn't exists\")\n",
        "    return directories\n",
        "  \n",
        "# Devuelve una colección con las imágenes y los labels de la ruta\n",
        "# -datadir: path donde se encuentran la colección de imágenes.\n",
        "# -shape: Dimensiones con las que se cargarán las imágenes.\n",
        "# -as_gray: Indica si la imagen se cargará en escala de grises.\n",
        "# -get_label_from_dir: (defecto True) específica si la categoría se lee del propio directorio\n",
        "def readDataset(data_dir, shape, as_gray, get_label_from_dir = True):\n",
        "    images = []\n",
        "    labels = []\n",
        "    directories = __get_directories(data_dir)\n",
        "    \n",
        "    images, labels = __read_images_labels_from_dir(data_dir, images, labels, shape, as_gray, get_label_from_dir)\n",
        "    \n",
        "    for d in directories:\n",
        "                \n",
        "        #Buscamos fotos en el directorio\n",
        "        images_dir = os.path.join(data_dir, d)\n",
        "        images, labels = __read_images_labels_from_dir(images_dir, images, labels, shape, as_gray, get_label_from_dir)\n",
        "       \n",
        "    return images, labels\n",
        "  \n",
        "# Devuelve una imagen\n",
        "# - path: ruta de la imagen.\n",
        "# - size: dimensión con la que se cargará la imagen.\n",
        "# - as_gray: True para cargar la imagen en escala de grises.\n",
        "\n",
        "def load_image(path, size, as_gray):\n",
        "    aux = skimage.data.imread(path, as_gray = as_gray)\n",
        "    return skimage.transform.resize(aux, size, mode='constant')\n",
        "  \n",
        "# Devuelve una lista con los datos del fichero csv.\n",
        "# - path: ruta hasta el fichero csv.\n",
        "# - delimeter: Carácter delimitador de campos\n",
        "\n",
        "def read_csv(path, delimiter):\n",
        "    file = open(path)\n",
        "    title_csv = csv.reader(file, delimiter = delimiter)\n",
        "    return list(title_csv)\n",
        "  \n",
        "# Imprime los tamaños de las colecciones\n",
        "# - images: lista de imágenes precargadas.\n",
        "# - labels: relación de las imágenes con las categorías a las que pertenecen.\n",
        "# - np_images: np.array con las imágenes precargadas.\n",
        "# - np_labels: np.array con las categorías precargadas.\n",
        "# - environment: string identificativo del entorno.\n",
        "\n",
        "def print_size_dataset(images, labels, np_images, np_labels, environment):\n",
        "    print(\"Total images (\" + environment + \"): \", len(images))\n",
        "    print(\"Total labels (\" + environment + \"): \", len(set(labels)))\n",
        "    print(\"Images shape: \", np_images.shape)\n",
        "    print(\"Labels shape: \", np_labels.shape)\n",
        "    \n",
        "# Imprime una matriz 32x32 con los diferentes tipos de señales que\n",
        "# se van a clasificar. Muestra la primera imagen de cada categoría.\n",
        "# - images: lista de imágenes precargadas.\n",
        "# - labels: relación de las imágenes con las categorías a las que pertenecen.\n",
        "# - titles: lista con los nombres de las categorías.\n",
        "\n",
        "def print_summary_dataset(images, labels, titles):\n",
        "    \n",
        "    #Quitamos los repetidos a los labels\n",
        "    unique_labels = set(labels)\n",
        "    \n",
        "    plt.figure(figsize=(32, 32))\n",
        "    i = 1\n",
        "    \n",
        "    for label in unique_labels:\n",
        "        \n",
        "        #Obtenemos la primera imagén de cada label\n",
        "        image = images[labels.index(label)]\n",
        "        plt.subplot(8, 8, i)\n",
        "        plt.axis('off')\n",
        "        plt.title(titles[i-1][1])\n",
        "        i += 1\n",
        "        _ = plt.imshow(image)\n",
        "        \n",
        "    plt.show()\n",
        "\n",
        "# Imprime todas las imágenes de una label especifica\n",
        "# - label: índice de la label que se quiere buscar.\n",
        "# - images: lista de imágenes precargadas.\n",
        "# - source: lista de la relación de etiquetas.\n",
        "# - titles: lista con las diferentes categorías de labels.\n",
        "\n",
        "def print_signals(label, images, source, titles):\n",
        "    \n",
        "    start, end = __get_start_end(label, source)\n",
        "    \n",
        "    if start < end:\n",
        "        rows = (end - start) / 8\n",
        "\n",
        "        print(\"Signal: \", titles[label][1])\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        i = 1\n",
        "\n",
        "        for image in images[start:end]:\n",
        "            plt.subplot(rows + 1, 8, i)\n",
        "            plt.axis('off')\n",
        "            i += 1\n",
        "            plt.imshow(image)\n",
        "\n",
        "        plt.show()\n",
        "        \n",
        "# Imprime los atributos de las imágenes de una label especifica.\n",
        "# - label: índice de la label que se quiere buscar.\n",
        "# - images: lista de imágenes precargadas.\n",
        "# - source: lista de la relación de etiquetas.\n",
        "# - titles: lista con las diferentes categorías de labels.\n",
        "\n",
        "def print_signals_attributes(label, images, source, titles):\n",
        "    \n",
        "    start, end = __get_start_end(label, source)\n",
        "    \n",
        "    if start < end:\n",
        "        print(\"Signal: \", titles[label][1])\n",
        "        for image in images[start:end]:\n",
        "            print(\"shape: \", image.shape, \"\\tmin:\", image.min(), \"\\tmax: \", image.max())\n",
        "            \n",
        "# Devuelve una lista con las categorías de las imágenes de prueba leídas del fichero csv.\n",
        "# - csv: fichero csv\n",
        "# - class_column: número de columna que contiene las clases.\n",
        "# - first_is_header: Indica si la primera fila es una cabecerá.\n",
        "\n",
        "def get_class_id_array(csv, class_column, first_is_header = True):\n",
        "    labels = []\n",
        "    for row in csv:\n",
        "        if not first_is_header:\n",
        "            labels.append(int(row[class_column]))\n",
        "        else:\n",
        "            first_is_header = False\n",
        "    \n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WZtFcFKbB6-",
        "colab_type": "code",
        "outputId": "6eb07c70-4911-4977-dfd8-ffbee2afa7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Mostramos información de CPU & GPU\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 14237383696818439362\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 18346665061786467070\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 17489262739820913928\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14800692839\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 7700283072637644804\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpZFFb5OZ3Dg",
        "colab_type": "code",
        "outputId": "dca76933-15e9-466f-abdd-380fff63827f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Obtenemos el directorio actual como trabajo.\n",
        "ROOT_PATH = os.getcwd()\n",
        "\n",
        "# Establecemos la dimensión de las imágenes.\n",
        "IMG_SHAPE = (32, 32)\n",
        "print(\"Tamaño de las imágenes de entrada: \", IMG_SHAPE)\n",
        "IMG_SHAPE_LEN = IMG_SHAPE[0] * IMG_SHAPE[1]\n",
        "print(\"Vectorizando la entrada, sería de un tamaño: \", IMG_SHAPE_LEN)\n",
        "\n",
        "# Obtenemos los paths de trabajo\n",
        "labels_path = os.path.join(ROOT_PATH, \"dataset_ger/labels.csv\")\n",
        "train_path = os.path.join(ROOT_PATH, \"dataset_ger/train/Images\")\n",
        "test_info_path = os.path.join(ROOT_PATH, \"dataset_ger/test/GT-final_test.csv\")\n",
        "test_path = os.path.join(ROOT_PATH, \"dataset_ger/test/Images\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño de las imágenes de entrada:  (32, 32)\n",
            "Vectorizando la entrada, sería de un tamaño:  1024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_55nevcUQHR",
        "colab_type": "code",
        "outputId": "d7892910-3db3-4edf-af17-3dafe7c281cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Cargamos las imágenes de entrenamiento.\n",
        "images_train, labels_train = readDataset(train_path, IMG_SHAPE, False)\n",
        "\n",
        "# Convertimos las listas a array numpy de float32\n",
        "np_images_train = np.asarray(images_train, dtype = np.float32)\n",
        "np_labels_train = np.asarray(labels_train, dtype = np.int8)\n",
        "\n",
        "# Recuperamos los nombres de las categorias. Los diferentes tipo de señales\n",
        "# que se van a clasificar.\n",
        "titles = read_csv(labels_path, \",\")\n",
        "\n",
        "# Se imprime información de los datos cargados.\n",
        "print_size_dataset(images_train, labels_train, np_images_train, np_labels_train, \"train\")\n",
        "print(\"Titles total: \", len(titles))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
            "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total images (train):  39209\n",
            "Total labels (train):  43\n",
            "Images shape:  (39209, 32, 32, 3)\n",
            "Labels shape:  (39209,)\n",
            "Titles total:  43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J8iZFpgC7tH",
        "colab_type": "code",
        "outputId": "cc64564d-4338-4698-d488-17b032d20f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Cargamos las imágenes de entrenamiento.\n",
        "images_test, labels_test = readDataset(test_path, IMG_SHAPE, False, False)\n",
        "\n",
        "test_info  = read_csv(test_info_path, \";\")\n",
        "labels_test = get_class_id_array(test_info, 7)\n",
        "\n",
        "# Convertimos las listas a array numpy de float32\n",
        "np_images_test = np.asarray(images_test, dtype = np.float32)\n",
        "np_labels_test = np.asarray(labels_test, dtype = np.int8)\n",
        "\n",
        "# Se imprime información de los datos cargados.\n",
        "print_size_dataset(images_test, labels_test, np_images_test, np_labels_test, \"test\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
            "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total images (test):  12630\n",
            "Total labels (test):  43\n",
            "Images shape:  (12630, 32, 32, 3)\n",
            "Labels shape:  (12630,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W2tKUgvUukC",
        "colab_type": "code",
        "outputId": "e67ddd4a-49e9-4cd5-ca11-54cabb3ea60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Convertimos las labels de manera categórica\n",
        "labels_categorical_train = keras.utils.to_categorical(np_labels_train)\n",
        "labels_categorical_test = keras.utils.to_categorical(np_labels_test)\n",
        "\n",
        "print(\"Ejemplo primera imagen de manera categórica: \", labels_categorical_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ejemplo primera imagen de manera categórica:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhL5rFelZfLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_keras_model():\n",
        "    # IMPLEMENTACIÓN RED NEURONAL\n",
        "    # En Keras la envoltura para cualquier red neuronal se crea con la clase Sequential\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (5, 5),\n",
        "                            activation='relu', input_shape=(IMG_SHAPE[0], IMG_SHAPE[1], 3)))\n",
        "    model.add(layers.MaxPooling2D(2, 2))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D(2, 2))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    \n",
        "    model.add(layers.MaxPooling2D(2, 2))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(len(set(labels_train)), activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Cucwmicr1K",
        "colab_type": "code",
        "outputId": "24ba5cdc-fbd1-44bd-9e4e-13cb4a9f78dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1380
        }
      },
      "source": [
        "model = get_keras_model()\n",
        "\n",
        "# Muestra la arquitectura de nuestra red neuronal\n",
        "model.summary()\n",
        "\n",
        "# Configurando el modelo de aprendijaze:\n",
        "#  · loss, función para evaluar el grado de error entre salidas calculadas\n",
        "#  · optimizador, función para calcular los pesos de los parámetros a partir de los datos de entrada\n",
        "#  · metricas, para monitorizar el proceso de aprendizaje de la red.\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=\"sgd\",\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "# - batch_size, indica el número de datos que se usan en cada actualización.\n",
        "# - epochs, indica el número de veces que se usan todos los datos del proceso.\n",
        "#model.fit(np_images_train, labels_categorical_train, batch_size=32, epochs=20)\n",
        "model.fit(np_images_train, labels_categorical_train,\n",
        "          batch_size = 32,\n",
        "          epochs = 20,\n",
        "          callbacks=[ModelCheckpoint('model_32_32_gpu_ger.h5', save_best_only = False)])\n",
        "\n",
        "# Evaluación del modelo\n",
        "test_loss, test_acc = model.evaluate(np_images_test, labels_categorical_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        2432      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 10, 10, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 43)                11051     \n",
            "=================================================================\n",
            "Total params: 64,747\n",
            "Trainable params: 64,747\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "39209/39209 [==============================] - 7s 186us/step - loss: 3.2841 - acc: 0.1409\n",
            "Epoch 2/20\n",
            "39209/39209 [==============================] - 5s 131us/step - loss: 2.4419 - acc: 0.3249\n",
            "Epoch 3/20\n",
            "39209/39209 [==============================] - 5s 133us/step - loss: 1.6752 - acc: 0.5233\n",
            "Epoch 4/20\n",
            "39209/39209 [==============================] - 5s 134us/step - loss: 1.1183 - acc: 0.6834\n",
            "Epoch 5/20\n",
            "39209/39209 [==============================] - 5s 133us/step - loss: 0.7871 - acc: 0.7824\n",
            "Epoch 6/20\n",
            "39209/39209 [==============================] - 6s 142us/step - loss: 0.5979 - acc: 0.8356\n",
            "Epoch 7/20\n",
            "39209/39209 [==============================] - 6s 151us/step - loss: 0.4801 - acc: 0.8695\n",
            "Epoch 8/20\n",
            "39209/39209 [==============================] - 5s 136us/step - loss: 0.4036 - acc: 0.8916\n",
            "Epoch 9/20\n",
            "39209/39209 [==============================] - 5s 132us/step - loss: 0.3506 - acc: 0.9042\n",
            "Epoch 10/20\n",
            "39209/39209 [==============================] - 5s 132us/step - loss: 0.3051 - acc: 0.9192\n",
            "Epoch 11/20\n",
            "39209/39209 [==============================] - 5s 132us/step - loss: 0.2740 - acc: 0.9278\n",
            "Epoch 12/20\n",
            "39209/39209 [==============================] - 5s 132us/step - loss: 0.2455 - acc: 0.9352\n",
            "Epoch 13/20\n",
            "39209/39209 [==============================] - 5s 132us/step - loss: 0.2299 - acc: 0.9385\n",
            "Epoch 14/20\n",
            "39209/39209 [==============================] - 5s 134us/step - loss: 0.2120 - acc: 0.9444\n",
            "Epoch 15/20\n",
            "39209/39209 [==============================] - 6s 150us/step - loss: 0.1944 - acc: 0.9477\n",
            "Epoch 16/20\n",
            "39209/39209 [==============================] - 5s 132us/step - loss: 0.1818 - acc: 0.9525\n",
            "Epoch 17/20\n",
            "39209/39209 [==============================] - 5s 132us/step - loss: 0.1722 - acc: 0.9544\n",
            "Epoch 18/20\n",
            "39209/39209 [==============================] - 5s 133us/step - loss: 0.1616 - acc: 0.9572\n",
            "Epoch 19/20\n",
            "39209/39209 [==============================] - 5s 131us/step - loss: 0.1512 - acc: 0.9604\n",
            "Epoch 20/20\n",
            "39209/39209 [==============================] - 5s 133us/step - loss: 0.1430 - acc: 0.9626\n",
            "12630/12630 [==============================] - 1s 59us/step\n",
            "Test loss: 12.99370772542221\n",
            "Test accuracy: 0.03602533650275553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgTG5A20csHI",
        "colab_type": "code",
        "outputId": "f61be4dd-5fc7-4448-d103-b1f19a215561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Evaluación del modelo\n",
        "test_loss, test_acc = model.evaluate(np_images_test, labels_categorical_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12630/12630 [==============================] - 1s 55us/step\n",
            "Test loss: 12.99370772542221\n",
            "Test accuracy: 0.03602533650275553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgI3rrdScsRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                             featurewise_std_normalization=False, \n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             zoom_range=0.2,\n",
        "                             shear_range=0.1,\n",
        "                             rotation_range=10.,)\n",
        "\n",
        "datagen.fit(np_images_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QftMYJbmcz3d",
        "colab_type": "code",
        "outputId": "6bfc1def-26b5-4af3-fe21-c6744c61c181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model_2 = get_keras_model()\n",
        "\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=\"sgd\",\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model_2.fit_generator(datagen.flow(np_images_train, labels_categorical_train, batch_size=32),\n",
        "                      steps_per_epoch = np_images_train.shape[0],\n",
        "                      epochs = 20,\n",
        "                      callbacks=[ModelCheckpoint('model_data_aug_32_32_gpu_ger.h5',save_best_only = False)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "39209/39209 [==============================] - 628s 16ms/step - loss: 0.8090 - acc: 0.7696\n",
            "Epoch 2/20\n",
            "39209/39209 [==============================] - 634s 16ms/step - loss: 0.2264 - acc: 0.9333\n",
            "Epoch 3/20\n",
            "39209/39209 [==============================] - 629s 16ms/step - loss: 0.1605 - acc: 0.9527\n",
            "Epoch 4/20\n",
            "39209/39209 [==============================] - 628s 16ms/step - loss: 0.1300 - acc: 0.9616\n",
            "Epoch 5/20\n",
            "39209/39209 [==============================] - 627s 16ms/step - loss: 0.1108 - acc: 0.9672\n",
            "Epoch 6/20\n",
            "39209/39209 [==============================] - 634s 16ms/step - loss: 0.0980 - acc: 0.9707\n",
            "Epoch 7/20\n",
            "39209/39209 [==============================] - 632s 16ms/step - loss: 0.0885 - acc: 0.9736\n",
            "Epoch 8/20\n",
            "39209/39209 [==============================] - 628s 16ms/step - loss: 0.0814 - acc: 0.9758\n",
            "Epoch 9/20\n",
            "39209/39209 [==============================] - 627s 16ms/step - loss: 0.0759 - acc: 0.9776\n",
            "Epoch 10/20\n",
            "39209/39209 [==============================] - 627s 16ms/step - loss: 0.0711 - acc: 0.9788\n",
            "Epoch 11/20\n",
            "39209/39209 [==============================] - 630s 16ms/step - loss: 0.0675 - acc: 0.9800\n",
            "Epoch 12/20\n",
            "39209/39209 [==============================] - 629s 16ms/step - loss: 0.0639 - acc: 0.9811\n",
            "Epoch 13/20\n",
            "39209/39209 [==============================] - 628s 16ms/step - loss: 0.0610 - acc: 0.9818\n",
            "Epoch 14/20\n",
            "39209/39209 [==============================] - 630s 16ms/step - loss: 0.0588 - acc: 0.9825\n",
            "Epoch 15/20\n",
            "39209/39209 [==============================] - 632s 16ms/step - loss: 0.0571 - acc: 0.9830\n",
            "Epoch 16/20\n",
            "39209/39209 [==============================] - 631s 16ms/step - loss: 0.0543 - acc: 0.9839\n",
            "Epoch 17/20\n",
            "39209/39209 [==============================] - 628s 16ms/step - loss: 0.0523 - acc: 0.9845\n",
            "Epoch 18/20\n",
            "39209/39209 [==============================] - 629s 16ms/step - loss: 0.0513 - acc: 0.9847\n",
            "Epoch 19/20\n",
            "39209/39209 [==============================] - 629s 16ms/step - loss: 0.0494 - acc: 0.9853\n",
            "Epoch 20/20\n",
            "39209/39209 [==============================] - 633s 16ms/step - loss: 0.0489 - acc: 0.9856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb75c4a4668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nej9Qatoc0Gd",
        "colab_type": "code",
        "outputId": "a53ca994-58bc-437e-c9c5-90ed70a21358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Evaluación del modelo\n",
        "test_loss, test_acc = model_2.evaluate(np_images_test, labels_categorical_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12630/12630 [==============================] - 1s 71us/step\n",
            "Test loss: 14.951218102908946\n",
            "Test accuracy: 0.0371338083950754\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}