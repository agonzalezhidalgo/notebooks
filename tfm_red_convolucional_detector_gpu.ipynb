{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbqHfvwZHnk4"
   },
   "outputs": [],
   "source": [
    "# Instalamos KERAS\n",
    "!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ODuccLWZZxJE",
    "outputId": "1de3b904-3807-40e5-b54c-d86a1da0b87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dataset_detector'...\n",
      "remote: Enumerating objects: 29652, done.\u001b[K\n",
      "remote: Counting objects: 100% (29652/29652), done.\u001b[K\n",
      "remote: Compressing objects: 100% (28571/28571), done.\u001b[K\n",
      "remote: Total 29652 (delta 1082), reused 29649 (delta 1081), pack-reused 0\n",
      "Receiving objects: 100% (29652/29652), 877.02 MiB | 30.68 MiB/s, done.\n",
      "Resolving deltas: 100% (1082/1082), done.\n",
      "Checking out files: 100% (30510/30510), done.\n"
     ]
    }
   ],
   "source": [
    "# Descargamos el dataset\n",
    "!git clone https://github.com/agonzalezhidalgo/dataset_detector.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uDKgXudXaYJF",
    "outputId": "a2087b47-023d-44e5-8681-592124369214"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-image.org/docs/stable/api/api.html\n",
    "import skimage\n",
    "\n",
    "# https://docs.python.org/3/library/csv.html\n",
    "import csv\n",
    "\n",
    "# https://matplotlib.org/api/index.html\n",
    "import matplotlib\n",
    "\n",
    "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# https://docs.python.org/3/library/os.html\n",
    "import os\n",
    "\n",
    "# https://docs.scipy.org/doc/numpy/reference/\n",
    "import numpy as np\n",
    "\n",
    "# https://keras.io/models/model/\n",
    "import keras\n",
    "\n",
    "from keras import models\n",
    "\n",
    "# Core Layers: https://keras.io/layers/core/\n",
    "# Convolution Layers: https://keras.io/layers/convolutional/\n",
    "from keras import layers\n",
    "\n",
    "# https://keras.io/preprocessing/image/\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# https://keras.io/callbacks/\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16_v-R69B9XO"
   },
   "source": [
    "Celda con funciones generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jP7IhbsUOsc"
   },
   "outputs": [],
   "source": [
    "# Devuelve las imagenes y etiquetas de una carpeta especifíca\n",
    "def __read_images_labels_from_dir(directory, images, labels, shape, as_gray, get_label_from_dir):\n",
    "    \n",
    "    #Buscamos fotos en el directorio\n",
    "    for f in os.listdir(directory):\n",
    "        # Cargamos archivos con extension .ppm \n",
    "        # Obviamos el color y lo cargamos como escala de grises y normalizamos el tamaño\n",
    "        if f.endswith(\".ppm\"):\n",
    "            image = load_image(os.path.join(directory, f), shape, as_gray)\n",
    "            images.append(image)\n",
    "            if get_label_from_dir:\n",
    "                labels.append(int(os.path.basename(directory)))\n",
    "    \n",
    "    return images, labels\n",
    "  \n",
    "# Obtenemos el índice inicial y final de una label específica\n",
    "# - label: índice de la label que se quiere buscar.\n",
    "# - source: lista de la relación de etiquetas.\n",
    "\n",
    "def __get_start_end(label, source):\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    try:        \n",
    "        start = source.index(label)\n",
    "        end = start + source.count(label)\n",
    "\n",
    "    except:\n",
    "        print(\"label doesn't exist\")\n",
    "\n",
    "    return start, end\n",
    "  \n",
    "# Devuelve una colección de directorios de la ruta\n",
    "def __get_directories(data_dir):\n",
    "    \n",
    "    directories = []\n",
    "    \n",
    "    if os.path.exists(data_dir):\n",
    "        \n",
    "        #Buscamos todos los directorios de la ruta\n",
    "        for d in os.listdir(data_dir):\n",
    "            if os.path.isdir(os.path.join(data_dir, d)):\n",
    "                directories.append(d)\n",
    "                \n",
    "    else:\n",
    "        print(\"path doesn't exists\")\n",
    "    return directories\n",
    "  \n",
    "# Devuelve una colección con las imágenes y los labels de la ruta\n",
    "# -datadir: path donde se encuentran la colección de imágenes.\n",
    "# -shape: Dimensiones con las que se cargarán las imágenes.\n",
    "# -as_gray: Indica si la imagen se cargará en escala de grises.\n",
    "# -get_label_from_dir: (defecto True) específica si la categoría se lee del propio directorio\n",
    "def readDataset(data_dir, shape, as_gray, get_label_from_dir = True):\n",
    "    images = []\n",
    "    labels = []\n",
    "    directories = __get_directories(data_dir)\n",
    "    \n",
    "    images, labels = __read_images_labels_from_dir(data_dir, images, labels, shape, as_gray, get_label_from_dir)\n",
    "    \n",
    "    for d in directories:\n",
    "                \n",
    "        #Buscamos fotos en el directorio\n",
    "        images_dir = os.path.join(data_dir, d)\n",
    "        images, labels = __read_images_labels_from_dir(images_dir, images, labels, shape, as_gray, get_label_from_dir)\n",
    "       \n",
    "    return images, labels\n",
    "  \n",
    "# Devuelve una imagen\n",
    "# - path: ruta de la imagen.\n",
    "# - size: dimensión con la que se cargará la imagen.\n",
    "# - as_gray: True para cargar la imagen en escala de grises.\n",
    "\n",
    "def load_image(path, size, as_gray):\n",
    "    aux = skimage.data.imread(path, as_gray = as_gray)\n",
    "    return skimage.transform.resize(aux, size, mode='constant')\n",
    "  \n",
    "# Devuelve una lista con los datos del fichero csv.\n",
    "# - path: ruta hasta el fichero csv.\n",
    "# - delimeter: Carácter delimitador de campos\n",
    "\n",
    "def read_csv(path, delimiter):\n",
    "    file = open(path)\n",
    "    title_csv = csv.reader(file, delimiter = delimiter)\n",
    "    return list(title_csv)\n",
    "  \n",
    "# Imprime los tamaños de las colecciones\n",
    "# - images: lista de imágenes precargadas.\n",
    "# - labels: relación de las imágenes con las categorías a las que pertenecen.\n",
    "# - np_images: np.array con las imágenes precargadas.\n",
    "# - np_labels: np.array con las categorías precargadas.\n",
    "# - environment: string identificativo del entorno.\n",
    "\n",
    "def print_size_dataset(images, labels, np_images, np_labels, environment):\n",
    "    print(\"Total images (\" + environment + \"): \", len(images))\n",
    "    print(\"Total labels (\" + environment + \"): \", len(set(labels)))\n",
    "    print(\"Images shape: \", np_images.shape)\n",
    "    print(\"Labels shape: \", np_labels.shape)\n",
    "    \n",
    "# Imprime una matriz 32x32 con los diferentes tipos de señales que\n",
    "# se van a clasificar. Muestra la primera imagen de cada categoría.\n",
    "# - images: lista de imágenes precargadas.\n",
    "# - labels: relación de las imágenes con las categorías a las que pertenecen.\n",
    "# - titles: lista con los nombres de las categorías.\n",
    "\n",
    "def print_summary_dataset(images, labels, titles):\n",
    "    \n",
    "    #Quitamos los repetidos a los labels\n",
    "    unique_labels = set(labels)\n",
    "    \n",
    "    plt.figure(figsize=(32, 32))\n",
    "    i = 1\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        \n",
    "        #Obtenemos la primera imagén de cada label\n",
    "        image = images[labels.index(label)]\n",
    "        plt.subplot(8, 8, i)\n",
    "        plt.axis('off')\n",
    "        plt.title(titles[i-1][1])\n",
    "        i += 1\n",
    "        _ = plt.imshow(image)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "# Imprime todas las imágenes de una label especifica\n",
    "# - label: índice de la label que se quiere buscar.\n",
    "# - images: lista de imágenes precargadas.\n",
    "# - source: lista de la relación de etiquetas.\n",
    "# - titles: lista con las diferentes categorías de labels.\n",
    "\n",
    "def print_signals(label, images, source, titles):\n",
    "    \n",
    "    start, end = __get_start_end(label, source)\n",
    "    \n",
    "    if start < end:\n",
    "        rows = (end - start) / 8\n",
    "\n",
    "        print(\"Signal: \", titles[label][1])\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        i = 1\n",
    "\n",
    "        for image in images[start:end]:\n",
    "            plt.subplot(rows + 1, 8, i)\n",
    "            plt.axis('off')\n",
    "            i += 1\n",
    "            plt.imshow(image)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "# Imprime los atributos de las imágenes de una label especifica.\n",
    "# - label: índice de la label que se quiere buscar.\n",
    "# - images: lista de imágenes precargadas.\n",
    "# - source: lista de la relación de etiquetas.\n",
    "# - titles: lista con las diferentes categorías de labels.\n",
    "\n",
    "def print_signals_attributes(label, images, source, titles):\n",
    "    \n",
    "    start, end = __get_start_end(label, source)\n",
    "    \n",
    "    if start < end:\n",
    "        print(\"Signal: \", titles[label][1])\n",
    "        for image in images[start:end]:\n",
    "            print(\"shape: \", image.shape, \"\\tmin:\", image.min(), \"\\tmax: \", image.max())\n",
    "            \n",
    "# Devuelve una lista con las categorías de las imágenes de prueba leídas del fichero csv.\n",
    "# - csv: fichero csv\n",
    "# - class_column: número de columna que contiene las clases.\n",
    "# - first_is_header: Indica si la primera fila es una cabecerá.\n",
    "\n",
    "def get_class_id_array(csv, class_column, first_is_header = True):\n",
    "    labels = []\n",
    "    for row in csv:\n",
    "        if not first_is_header:\n",
    "            labels.append(int(row[class_column]))\n",
    "        else:\n",
    "            first_is_header = False\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "3WZtFcFKbB6-",
    "outputId": "34b37ce7-1511-4e9f-8d48-5971cdf0e01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1731755466473237525\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9829624130609613921\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 10969816919185812521\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14892338381\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14136930018601045405\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Mostramos información de CPU & GPU\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MpZFFb5OZ3Dg",
    "outputId": "5e69b4ca-8970-42e6-8de5-4c1920ee667b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de las imágenes de entrada:  (64, 64)\n",
      "Vectorizando la entrada, sería de un tamaño:  4096\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos el directorio actual como trabajo.\n",
    "ROOT_PATH = os.getcwd()\n",
    "\n",
    "# Establecemos la dimensión de las imágenes.\n",
    "IMG_SHAPE = (64, 64)\n",
    "print(\"Tamaño de las imágenes de entrada: \", IMG_SHAPE)\n",
    "IMG_SHAPE_LEN = IMG_SHAPE[0] * IMG_SHAPE[1]\n",
    "print(\"Vectorizando la entrada, sería de un tamaño: \", IMG_SHAPE_LEN)\n",
    "\n",
    "# Obtenemos los paths de trabajo\n",
    "train_path = os.path.join(ROOT_PATH, \"dataset_detector/train\")\n",
    "test_path = os.path.join(ROOT_PATH, \"dataset_detector/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "n_55nevcUQHR",
    "outputId": "d24de2e5-24a0-45da-8509-8222de322928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images (train):  15481\n",
      "Total labels (train):  2\n",
      "Images shape:  (15481, 64, 64, 3)\n",
      "Labels shape:  (15481,)\n",
      "Total images (test):  14726\n",
      "Total labels (test):  2\n",
      "Images shape:  (14726, 64, 64, 3)\n",
      "Labels shape:  (14726,)\n"
     ]
    }
   ],
   "source": [
    "# Cargamos las imágenes de entrenamiento y de test.\n",
    "images_train, labels_train = readDataset(train_path, IMG_SHAPE, False)\n",
    "images_test, labels_test = readDataset(test_path, IMG_SHAPE, False)\n",
    "\n",
    "# Convertimos las listas a array numpy de float32\n",
    "np_images_train = np.asarray(images_train, dtype = np.float32)\n",
    "np_labels_train = np.asarray(labels_train, dtype = np.int8)\n",
    "\n",
    "np_images_test = np.asarray(images_test, dtype = np.float32)\n",
    "np_labels_test = np.asarray(labels_test, dtype = np.int8)\n",
    "\n",
    "\n",
    "# Se imprime información de los datos cargados.\n",
    "print_size_dataset(images_train, labels_train, np_images_train, np_labels_train, \"train\")\n",
    "print_size_dataset(images_test, labels_test, np_images_test, np_labels_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2W2tKUgvUukC",
    "outputId": "d7d80ced-9f45-46c3-a24a-d08ab9380e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo primera imagen de manera categórica:  [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Convertimos las labels de manera categórica\n",
    "labels_categorical_train = keras.utils.to_categorical(np_labels_train)\n",
    "labels_categorical_test = keras.utils.to_categorical(np_labels_test)\n",
    "\n",
    "print(\"Ejemplo primera imagen de manera categórica: \", labels_categorical_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhL5rFelZfLv"
   },
   "outputs": [],
   "source": [
    "def get_keras_model():\n",
    "    # IMPLEMENTACIÓN RED NEURONAL\n",
    "    # En Keras la envoltura para cualquier red neuronal se crea con la clase Sequential\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (5, 5),\n",
    "                            activation='elu', input_shape=(IMG_SHAPE[0], IMG_SHAPE[1], 3)))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (5, 5), activation='elu'))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), activation='elu'))\n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    model.add(layers.MaxPooling2D(2, 2))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(len(set(labels_train)), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1006
    },
    "colab_type": "code",
    "id": "r8Cucwmicr1K",
    "outputId": "c46b5ee2-1844-4f2a-d693-0cc0d3f6b7b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0616 10:57:18.848674 139743172458368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0616 10:57:18.859019 139743172458368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0616 10:57:18.869326 139743172458368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0616 10:57:18.894334 139743172458368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0616 10:57:18.897216 139743172458368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0616 10:57:18.906621 139743172458368 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0616 10:57:19.019933 139743172458368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0616 10:57:19.041539 139743172458368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0616 10:57:19.149409 139743172458368 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 259,650\n",
      "Trainable params: 259,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "14726/14726 [==============================] - 2s 108us/step\n",
      "Test loss: 2.1343905477821057\n",
      "Test accuracy: 0.8010321879587662\n"
     ]
    }
   ],
   "source": [
    "model = get_keras_model()\n",
    "\n",
    "# Muestra la arquitectura de nuestra red neuronal\n",
    "model.summary()\n",
    "\n",
    "# Configurando el modelo de aprendijaze:\n",
    "#  · loss, función para evaluar el grado de error entre salidas calculadas\n",
    "#  · optimizador, función para calcular los pesos de los parámetros a partir de los datos de entrada\n",
    "#  · metricas, para monitorizar el proceso de aprendizaje de la red.\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "# - batch_size, indica el número de datos que se usan en cada actualización.\n",
    "# - epochs, indica el número de veces que se usan todos los datos del proceso.\n",
    "#model.fit(np_images_train, labels_categorical_train, batch_size=32, epochs=20)\n",
    "model.fit(np_images_train, labels_categorical_train,\n",
    "          batch_size = 64,\n",
    "          epochs = 25,\n",
    "          verbose = 0,\n",
    "          callbacks=[ModelCheckpoint('model_64_64_gpu_detector.h5', save_best_only = False)])\n",
    "\n",
    "# Evaluación del modelo\n",
    "test_loss, test_acc = model.evaluate(np_images_test, labels_categorical_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgI3rrdScsRg"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             featurewise_std_normalization=False, \n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10.,)\n",
    "\n",
    "datagen.fit(np_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "QftMYJbmcz3d",
    "outputId": "ac03d923-7fe0-41fb-b131-6ded2d48e2a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "15481/15481 [==============================] - 568s 37ms/step - loss: 0.0509 - acc: 0.9869\n",
      "Epoch 2/25\n",
      "15481/15481 [==============================] - 564s 36ms/step - loss: 0.0614 - acc: 0.9928\n",
      "Epoch 3/25\n",
      "15481/15481 [==============================] - 576s 37ms/step - loss: 0.1392 - acc: 0.9905\n",
      "Epoch 4/25\n",
      "15481/15481 [==============================] - 573s 37ms/step - loss: 0.3367 - acc: 0.9788\n",
      "Epoch 5/25\n",
      "15481/15481 [==============================] - 597s 39ms/step - loss: 0.3665 - acc: 0.9771\n",
      "Epoch 6/25\n",
      "15481/15481 [==============================] - 575s 37ms/step - loss: 0.4190 - acc: 0.9739\n",
      "Epoch 7/25\n",
      "15481/15481 [==============================] - 575s 37ms/step - loss: 0.4140 - acc: 0.9743\n",
      "Epoch 8/25\n",
      "15481/15481 [==============================] - 588s 38ms/step - loss: 0.7588 - acc: 0.9529\n",
      "Epoch 9/25\n",
      "15481/15481 [==============================] - 579s 37ms/step - loss: 0.8306 - acc: 0.9484\n",
      "Epoch 10/25\n",
      "15481/15481 [==============================] - 594s 38ms/step - loss: 0.5336 - acc: 0.9669\n",
      "Epoch 11/25\n",
      "15481/15481 [==============================] - 579s 37ms/step - loss: 3.7335 - acc: 0.7683\n",
      "Epoch 12/25\n",
      "15481/15481 [==============================] - 577s 37ms/step - loss: 11.8515 - acc: 0.2647\n",
      "Epoch 13/25\n",
      "15481/15481 [==============================] - 579s 37ms/step - loss: 1.4234 - acc: 0.9117\n",
      "Epoch 14/25\n",
      "15481/15481 [==============================] - 583s 38ms/step - loss: 0.4740 - acc: 0.9706\n",
      "Epoch 15/25\n",
      "15481/15481 [==============================] - 601s 39ms/step - loss: 0.4847 - acc: 0.9699\n",
      "Epoch 16/25\n",
      "15481/15481 [==============================] - 581s 38ms/step - loss: 0.8978 - acc: 0.9443\n",
      "Epoch 17/25\n",
      "15481/15481 [==============================] - 590s 38ms/step - loss: 0.6352 - acc: 0.9606\n",
      "Epoch 18/25\n",
      "15481/15481 [==============================] - 577s 37ms/step - loss: 0.8798 - acc: 0.9454\n",
      "Epoch 19/25\n",
      "15481/15481 [==============================] - 577s 37ms/step - loss: 1.6915 - acc: 0.8950\n",
      "Epoch 20/25\n",
      "15481/15481 [==============================] - 581s 38ms/step - loss: 1.8392 - acc: 0.8859\n",
      "Epoch 21/25\n",
      "15481/15481 [==============================] - 578s 37ms/step - loss: 0.8298 - acc: 0.9485\n",
      "Epoch 22/25\n",
      "15481/15481 [==============================] - 575s 37ms/step - loss: 0.5357 - acc: 0.9667\n",
      "Epoch 23/25\n",
      "15481/15481 [==============================] - 572s 37ms/step - loss: 0.5297 - acc: 0.9671\n",
      "Epoch 24/25\n",
      "15481/15481 [==============================] - 552s 36ms/step - loss: 0.8405 - acc: 0.9478\n",
      "Epoch 25/25\n",
      "15481/15481 [==============================] - 570s 37ms/step - loss: 1.7659 - acc: 0.8904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1820214240>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = get_keras_model()\n",
    "\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model_2.fit_generator(datagen.flow(np_images_train, labels_categorical_train, batch_size=32),\n",
    "                      steps_per_epoch = np_images_train.shape[0],\n",
    "                      epochs = 25,\n",
    "                      callbacks=[ModelCheckpoint('model_data_aug_64_64_gpu_detector.h5',save_best_only = False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "P5U-wVi-MUPd",
    "outputId": "1d58d9de-fcc9-4816-a0dc-4a32786f2a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14726/14726 [==============================] - 2s 119us/step\n",
      "Test loss: 2.3941728629674763\n",
      "Test accuracy: 0.8514192584463391\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo\n",
    "test_loss, test_acc = model_2.evaluate(np_images_test, labels_categorical_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "traffic_red_convolucional_gpu_detector",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
