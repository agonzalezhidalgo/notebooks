{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_red_convolucional_gpu_detector",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbqHfvwZHnk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instalamos KERAS\n",
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODuccLWZZxJE",
        "colab_type": "code",
        "outputId": "c91e74f8-e1c3-469d-cc1c-241dba457a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Descargamos el dataset\n",
        "!git clone https://github.com/agonzalezhidalgo/dataset_detector.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dataset_detector'...\n",
            "remote: Enumerating objects: 29649, done.\u001b[K\n",
            "remote: Counting objects: 100% (29649/29649), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28570/28570), done.\u001b[K\n",
            "remote: Total 29649 (delta 1080), reused 29645 (delta 1079), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (29649/29649), 877.01 MiB | 31.44 MiB/s, done.\n",
            "Resolving deltas: 100% (1080/1080), done.\n",
            "Checking out files: 100% (30510/30510), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDKgXudXaYJF",
        "colab_type": "code",
        "outputId": "347c6e66-c0e1-484d-8212-eb18776c1860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# http://scikit-image.org/docs/stable/api/api.html\n",
        "import skimage\n",
        "\n",
        "# https://docs.python.org/3/library/csv.html\n",
        "import csv\n",
        "\n",
        "# https://matplotlib.org/api/index.html\n",
        "import matplotlib\n",
        "\n",
        "# https://matplotlib.org/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# https://docs.python.org/3/library/os.html\n",
        "import os\n",
        "\n",
        "# https://docs.scipy.org/doc/numpy/reference/\n",
        "import numpy as np\n",
        "\n",
        "# https://keras.io/models/model/\n",
        "import keras\n",
        "\n",
        "from keras import models\n",
        "\n",
        "# Core Layers: https://keras.io/layers/core/\n",
        "# Convolution Layers: https://keras.io/layers/convolutional/\n",
        "from keras import layers\n",
        "\n",
        "# https://keras.io/preprocessing/image/\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# https://keras.io/callbacks/\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16_v-R69B9XO",
        "colab_type": "text"
      },
      "source": [
        "Celda con funciones generales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jP7IhbsUOsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Devuelve las imagenes y etiquetas de una carpeta especifíca\n",
        "def __read_images_labels_from_dir(directory, images, labels, shape, as_gray, get_label_from_dir):\n",
        "    \n",
        "    #Buscamos fotos en el directorio\n",
        "    for f in os.listdir(directory):\n",
        "        # Cargamos archivos con extension .ppm \n",
        "        # Obviamos el color y lo cargamos como escala de grises y normalizamos el tamaño\n",
        "        if f.endswith(\".ppm\"):\n",
        "            image = load_image(os.path.join(directory, f), shape, as_gray)\n",
        "            images.append(image)\n",
        "            if get_label_from_dir:\n",
        "                labels.append(int(os.path.basename(directory)))\n",
        "    \n",
        "    return images, labels\n",
        "  \n",
        "# Obtenemos el índice inicial y final de una label específica\n",
        "# - label: índice de la label que se quiere buscar.\n",
        "# - source: lista de la relación de etiquetas.\n",
        "\n",
        "def __get_start_end(label, source):\n",
        "\n",
        "    start = 0\n",
        "    end = 0\n",
        "    \n",
        "    try:        \n",
        "        start = source.index(label)\n",
        "        end = start + source.count(label)\n",
        "\n",
        "    except:\n",
        "        print(\"label doesn't exist\")\n",
        "\n",
        "    return start, end\n",
        "  \n",
        "# Devuelve una colección de directorios de la ruta\n",
        "def __get_directories(data_dir):\n",
        "    \n",
        "    directories = []\n",
        "    \n",
        "    if os.path.exists(data_dir):\n",
        "        \n",
        "        #Buscamos todos los directorios de la ruta\n",
        "        for d in os.listdir(data_dir):\n",
        "            if os.path.isdir(os.path.join(data_dir, d)):\n",
        "                directories.append(d)\n",
        "                \n",
        "    else:\n",
        "        print(\"path doesn't exists\")\n",
        "    return directories\n",
        "  \n",
        "# Devuelve una colección con las imágenes y los labels de la ruta\n",
        "# -datadir: path donde se encuentran la colección de imágenes.\n",
        "# -shape: Dimensiones con las que se cargarán las imágenes.\n",
        "# -as_gray: Indica si la imagen se cargará en escala de grises.\n",
        "# -get_label_from_dir: (defecto True) específica si la categoría se lee del propio directorio\n",
        "def readDataset(data_dir, shape, as_gray, get_label_from_dir = True):\n",
        "    images = []\n",
        "    labels = []\n",
        "    directories = __get_directories(data_dir)\n",
        "    \n",
        "    images, labels = __read_images_labels_from_dir(data_dir, images, labels, shape, as_gray, get_label_from_dir)\n",
        "    \n",
        "    for d in directories:\n",
        "                \n",
        "        #Buscamos fotos en el directorio\n",
        "        images_dir = os.path.join(data_dir, d)\n",
        "        images, labels = __read_images_labels_from_dir(images_dir, images, labels, shape, as_gray, get_label_from_dir)\n",
        "       \n",
        "    return images, labels\n",
        "  \n",
        "# Devuelve una imagen\n",
        "# - path: ruta de la imagen.\n",
        "# - size: dimensión con la que se cargará la imagen.\n",
        "# - as_gray: True para cargar la imagen en escala de grises.\n",
        "\n",
        "def load_image(path, size, as_gray):\n",
        "    aux = skimage.data.imread(path, as_gray = as_gray)\n",
        "    return skimage.transform.resize(aux, size, mode='constant')\n",
        "  \n",
        "# Devuelve una lista con los datos del fichero csv.\n",
        "# - path: ruta hasta el fichero csv.\n",
        "# - delimeter: Carácter delimitador de campos\n",
        "\n",
        "def read_csv(path, delimiter):\n",
        "    file = open(path)\n",
        "    title_csv = csv.reader(file, delimiter = delimiter)\n",
        "    return list(title_csv)\n",
        "  \n",
        "# Imprime los tamaños de las colecciones\n",
        "# - images: lista de imágenes precargadas.\n",
        "# - labels: relación de las imágenes con las categorías a las que pertenecen.\n",
        "# - np_images: np.array con las imágenes precargadas.\n",
        "# - np_labels: np.array con las categorías precargadas.\n",
        "# - environment: string identificativo del entorno.\n",
        "\n",
        "def print_size_dataset(images, labels, np_images, np_labels, environment):\n",
        "    print(\"Total images (\" + environment + \"): \", len(images))\n",
        "    print(\"Total labels (\" + environment + \"): \", len(set(labels)))\n",
        "    print(\"Images shape: \", np_images.shape)\n",
        "    print(\"Labels shape: \", np_labels.shape)\n",
        "    \n",
        "# Imprime una matriz 32x32 con los diferentes tipos de señales que\n",
        "# se van a clasificar. Muestra la primera imagen de cada categoría.\n",
        "# - images: lista de imágenes precargadas.\n",
        "# - labels: relación de las imágenes con las categorías a las que pertenecen.\n",
        "# - titles: lista con los nombres de las categorías.\n",
        "\n",
        "def print_summary_dataset(images, labels, titles):\n",
        "    \n",
        "    #Quitamos los repetidos a los labels\n",
        "    unique_labels = set(labels)\n",
        "    \n",
        "    plt.figure(figsize=(32, 32))\n",
        "    i = 1\n",
        "    \n",
        "    for label in unique_labels:\n",
        "        \n",
        "        #Obtenemos la primera imagén de cada label\n",
        "        image = images[labels.index(label)]\n",
        "        plt.subplot(8, 8, i)\n",
        "        plt.axis('off')\n",
        "        plt.title(titles[i-1][1])\n",
        "        i += 1\n",
        "        _ = plt.imshow(image)\n",
        "        \n",
        "    plt.show()\n",
        "\n",
        "# Imprime todas las imágenes de una label especifica\n",
        "# - label: índice de la label que se quiere buscar.\n",
        "# - images: lista de imágenes precargadas.\n",
        "# - source: lista de la relación de etiquetas.\n",
        "# - titles: lista con las diferentes categorías de labels.\n",
        "\n",
        "def print_signals(label, images, source, titles):\n",
        "    \n",
        "    start, end = __get_start_end(label, source)\n",
        "    \n",
        "    if start < end:\n",
        "        rows = (end - start) / 8\n",
        "\n",
        "        print(\"Signal: \", titles[label][1])\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        i = 1\n",
        "\n",
        "        for image in images[start:end]:\n",
        "            plt.subplot(rows + 1, 8, i)\n",
        "            plt.axis('off')\n",
        "            i += 1\n",
        "            plt.imshow(image)\n",
        "\n",
        "        plt.show()\n",
        "        \n",
        "# Imprime los atributos de las imágenes de una label especifica.\n",
        "# - label: índice de la label que se quiere buscar.\n",
        "# - images: lista de imágenes precargadas.\n",
        "# - source: lista de la relación de etiquetas.\n",
        "# - titles: lista con las diferentes categorías de labels.\n",
        "\n",
        "def print_signals_attributes(label, images, source, titles):\n",
        "    \n",
        "    start, end = __get_start_end(label, source)\n",
        "    \n",
        "    if start < end:\n",
        "        print(\"Signal: \", titles[label][1])\n",
        "        for image in images[start:end]:\n",
        "            print(\"shape: \", image.shape, \"\\tmin:\", image.min(), \"\\tmax: \", image.max())\n",
        "            \n",
        "# Devuelve una lista con las categorías de las imágenes de prueba leídas del fichero csv.\n",
        "# - csv: fichero csv\n",
        "# - class_column: número de columna que contiene las clases.\n",
        "# - first_is_header: Indica si la primera fila es una cabecerá.\n",
        "\n",
        "def get_class_id_array(csv, class_column, first_is_header = True):\n",
        "    labels = []\n",
        "    for row in csv:\n",
        "        if not first_is_header:\n",
        "            labels.append(int(row[class_column]))\n",
        "        else:\n",
        "            first_is_header = False\n",
        "    \n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WZtFcFKbB6-",
        "colab_type": "code",
        "outputId": "aa85b236-7fba-400a-8166-869b274fa85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "# Mostramos información de CPU & GPU\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 6591234050081998241\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 16894059133533431556\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 2859374630618488523\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14800692839\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 6888324098725513013\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpZFFb5OZ3Dg",
        "colab_type": "code",
        "outputId": "41b53a8c-04c9-42e5-ffa4-5aee45c3a4b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Obtenemos el directorio actual como trabajo.\n",
        "ROOT_PATH = os.getcwd()\n",
        "\n",
        "# Establecemos la dimensión de las imágenes.\n",
        "IMG_SHAPE = (64, 64)\n",
        "print(\"Tamaño de las imágenes de entrada: \", IMG_SHAPE)\n",
        "IMG_SHAPE_LEN = IMG_SHAPE[0] * IMG_SHAPE[1]\n",
        "print(\"Vectorizando la entrada, sería de un tamaño: \", IMG_SHAPE_LEN)\n",
        "\n",
        "# Obtenemos los paths de trabajo\n",
        "train_path = os.path.join(ROOT_PATH, \"dataset_detector/train\")\n",
        "test_path = os.path.join(ROOT_PATH, \"dataset_detector/test\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño de las imágenes de entrada:  (64, 64)\n",
            "Vectorizando la entrada, sería de un tamaño:  4096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_55nevcUQHR",
        "colab_type": "code",
        "outputId": "dc0ebbb0-435c-4b30-dd28-61f746b61175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Cargamos las imágenes de entrenamiento y de test.\n",
        "images_train, labels_train = readDataset(train_path, IMG_SHAPE, False)\n",
        "images_test, labels_test = readDataset(test_path, IMG_SHAPE, False)\n",
        "\n",
        "# Convertimos las listas a array numpy de float32\n",
        "np_images_train = np.asarray(images_train, dtype = np.float32)\n",
        "np_labels_train = np.asarray(labels_train, dtype = np.int8)\n",
        "\n",
        "np_images_test = np.asarray(images_test, dtype = np.float32)\n",
        "np_labels_test = np.asarray(labels_test, dtype = np.int8)\n",
        "\n",
        "\n",
        "# Se imprime información de los datos cargados.\n",
        "print_size_dataset(images_train, labels_train, np_images_train, np_labels_train, \"train\")\n",
        "print_size_dataset(images_test, labels_test, np_images_test, np_labels_test, \"test\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
            "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total images (train):  15481\n",
            "Total labels (train):  2\n",
            "Images shape:  (15481, 64, 64, 3)\n",
            "Labels shape:  (15481,)\n",
            "Total images (test):  14726\n",
            "Total labels (test):  2\n",
            "Images shape:  (14726, 64, 64, 3)\n",
            "Labels shape:  (14726,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W2tKUgvUukC",
        "colab_type": "code",
        "outputId": "17116eab-d521-46f4-e6be-d8efc3d30847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Convertimos las labels de manera categórica\n",
        "labels_categorical_train = keras.utils.to_categorical(np_labels_train)\n",
        "labels_categorical_test = keras.utils.to_categorical(np_labels_test)\n",
        "\n",
        "print(\"Ejemplo primera imagen de manera categórica: \", labels_categorical_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ejemplo primera imagen de manera categórica:  [0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhL5rFelZfLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_keras_model():\n",
        "    # IMPLEMENTACIÓN RED NEURONAL\n",
        "    # En Keras la envoltura para cualquier red neuronal se crea con la clase Sequential\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, (5, 5),\n",
        "                            activation='relu', input_shape=(IMG_SHAPE[0], IMG_SHAPE[1], 3)))\n",
        "    model.add(layers.MaxPooling2D(2, 2))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "\n",
        "    model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D(2, 2))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    \n",
        "    model.add(layers.Conv2D(128, (5, 5), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D(2, 2))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    \n",
        "    model.add(layers.MaxPooling2D(2, 2))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(len(set(labels_train)), activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Cucwmicr1K",
        "colab_type": "code",
        "outputId": "8f194a54-579d-474f-f071-9ccd9472d614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1482
        }
      },
      "source": [
        "model = get_keras_model()\n",
        "\n",
        "# Muestra la arquitectura de nuestra red neuronal\n",
        "model.summary()\n",
        "\n",
        "# Configurando el modelo de aprendijaze:\n",
        "#  · loss, función para evaluar el grado de error entre salidas calculadas\n",
        "#  · optimizador, función para calcular los pesos de los parámetros a partir de los datos de entrada\n",
        "#  · metricas, para monitorizar el proceso de aprendizaje de la red.\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=\"sgd\",\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "# - batch_size, indica el número de datos que se usan en cada actualización.\n",
        "# - epochs, indica el número de veces que se usan todos los datos del proceso.\n",
        "#model.fit(np_images_train, labels_categorical_train, batch_size=32, epochs=20)\n",
        "model.fit(np_images_train, labels_categorical_train,\n",
        "          batch_size = 32,\n",
        "          epochs = 20,\n",
        "          callbacks=[ModelCheckpoint('model_64_64_gpu_detector.h5', save_best_only = False)])\n",
        "\n",
        "# Evaluación del modelo\n",
        "test_loss, test_acc = model.evaluate(np_images_test, labels_categorical_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 60, 60, 32)        2432      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 64)        51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 9, 9, 128)         204928    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 259,650\n",
            "Trainable params: 259,650\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            "15481/15481 [==============================] - 8s 505us/step - loss: 0.3756 - acc: 0.8454\n",
            "Epoch 2/20\n",
            "15481/15481 [==============================] - 4s 250us/step - loss: 0.1797 - acc: 0.9404\n",
            "Epoch 3/20\n",
            "15481/15481 [==============================] - 4s 254us/step - loss: 0.1274 - acc: 0.9596\n",
            "Epoch 4/20\n",
            "15481/15481 [==============================] - 4s 253us/step - loss: 0.1050 - acc: 0.9663\n",
            "Epoch 5/20\n",
            "15481/15481 [==============================] - 4s 252us/step - loss: 0.0893 - acc: 0.9711\n",
            "Epoch 6/20\n",
            "15481/15481 [==============================] - 4s 256us/step - loss: 0.0798 - acc: 0.9749\n",
            "Epoch 7/20\n",
            "15481/15481 [==============================] - 4s 253us/step - loss: 0.0728 - acc: 0.9772\n",
            "Epoch 8/20\n",
            "15481/15481 [==============================] - 4s 254us/step - loss: 0.0666 - acc: 0.9778\n",
            "Epoch 9/20\n",
            "15481/15481 [==============================] - 4s 256us/step - loss: 0.0605 - acc: 0.9804\n",
            "Epoch 10/20\n",
            "15481/15481 [==============================] - 4s 254us/step - loss: 0.0554 - acc: 0.9830\n",
            "Epoch 11/20\n",
            "15481/15481 [==============================] - 4s 253us/step - loss: 0.0487 - acc: 0.9836\n",
            "Epoch 12/20\n",
            "15481/15481 [==============================] - 4s 255us/step - loss: 0.0476 - acc: 0.9850\n",
            "Epoch 13/20\n",
            "15481/15481 [==============================] - 4s 257us/step - loss: 0.0438 - acc: 0.9853\n",
            "Epoch 14/20\n",
            "15481/15481 [==============================] - 4s 270us/step - loss: 0.0405 - acc: 0.9859\n",
            "Epoch 15/20\n",
            "15481/15481 [==============================] - 4s 268us/step - loss: 0.0359 - acc: 0.9880\n",
            "Epoch 16/20\n",
            "15481/15481 [==============================] - 4s 255us/step - loss: 0.0331 - acc: 0.9895\n",
            "Epoch 17/20\n",
            "15481/15481 [==============================] - 4s 252us/step - loss: 0.0307 - acc: 0.9909\n",
            "Epoch 18/20\n",
            "15481/15481 [==============================] - 4s 254us/step - loss: 0.0308 - acc: 0.9899\n",
            "Epoch 19/20\n",
            "15481/15481 [==============================] - 4s 256us/step - loss: 0.0276 - acc: 0.9910\n",
            "Epoch 20/20\n",
            "15481/15481 [==============================] - 4s 251us/step - loss: 0.0266 - acc: 0.9910\n",
            "14726/14726 [==============================] - 2s 105us/step\n",
            "Test loss: 0.6082813204155455\n",
            "Test accuracy: 0.7424962651093304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgTG5A20csHI",
        "colab_type": "code",
        "outputId": "e01e9f8e-9b94-4ec4-b90e-bbed5ba90f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Evaluación del modelo\n",
        "test_loss, test_acc = model.evaluate(np_images_test, labels_categorical_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14726/14726 [==============================] - 2s 103us/step\n",
            "Test loss: 0.6082813204155455\n",
            "Test accuracy: 0.7424962651093304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgI3rrdScsRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                             featurewise_std_normalization=False, \n",
        "                             width_shift_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             zoom_range=0.2,\n",
        "                             shear_range=0.1,\n",
        "                             rotation_range=10.,)\n",
        "\n",
        "datagen.fit(np_images_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QftMYJbmcz3d",
        "colab_type": "code",
        "outputId": "551fd68e-109f-4a56-f744-2848f6c2d718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model_2 = get_keras_model()\n",
        "\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=\"sgd\",\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model_2.fit_generator(datagen.flow(np_images_train, labels_categorical_train, batch_size=32),\n",
        "                      steps_per_epoch = np_images_train.shape[0],\n",
        "                      epochs = 20,\n",
        "                      callbacks=[ModelCheckpoint('model_data_aug_64_64_gpu_detector.h5',save_best_only = False)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15481/15481 [==============================] - 561s 36ms/step - loss: 0.0712 - acc: 0.9755\n",
            "Epoch 2/20\n",
            "15481/15481 [==============================] - 556s 36ms/step - loss: 0.0139 - acc: 0.9954\n",
            "Epoch 3/20\n",
            "15481/15481 [==============================] - 555s 36ms/step - loss: 0.0072 - acc: 0.9977\n",
            "Epoch 4/20\n",
            "15481/15481 [==============================] - 558s 36ms/step - loss: 0.0046 - acc: 0.9985\n",
            "Epoch 5/20\n",
            "15481/15481 [==============================] - 562s 36ms/step - loss: 0.0033 - acc: 0.9990\n",
            "Epoch 6/20\n",
            "15481/15481 [==============================] - 559s 36ms/step - loss: 0.0026 - acc: 0.9992\n",
            "Epoch 7/20\n",
            "15481/15481 [==============================] - 558s 36ms/step - loss: 0.0021 - acc: 0.9993\n",
            "Epoch 8/20\n",
            "15481/15481 [==============================] - 561s 36ms/step - loss: 0.0015 - acc: 0.9996\n",
            "Epoch 9/20\n",
            "15481/15481 [==============================] - 557s 36ms/step - loss: 0.0015 - acc: 0.9995\n",
            "Epoch 10/20\n",
            "15481/15481 [==============================] - 563s 36ms/step - loss: 0.0012 - acc: 0.9997\n",
            "Epoch 11/20\n",
            "15481/15481 [==============================] - 558s 36ms/step - loss: 0.0012 - acc: 0.9997\n",
            "Epoch 12/20\n",
            "15481/15481 [==============================] - 556s 36ms/step - loss: 0.0011 - acc: 0.9997\n",
            "Epoch 13/20\n",
            "15481/15481 [==============================] - 558s 36ms/step - loss: 8.4663e-04 - acc: 0.9998\n",
            "Epoch 14/20\n",
            "15481/15481 [==============================] - 556s 36ms/step - loss: 6.6101e-04 - acc: 0.9998\n",
            "Epoch 15/20\n",
            "15481/15481 [==============================] - 559s 36ms/step - loss: 7.4390e-04 - acc: 0.9998\n",
            "Epoch 16/20\n",
            "15481/15481 [==============================] - 561s 36ms/step - loss: 6.8475e-04 - acc: 0.9998\n",
            "Epoch 17/20\n",
            "15481/15481 [==============================] - 559s 36ms/step - loss: 6.4629e-04 - acc: 0.9998\n",
            "Epoch 18/20\n",
            "15481/15481 [==============================] - 559s 36ms/step - loss: 5.9648e-04 - acc: 0.9998\n",
            "Epoch 19/20\n",
            "15481/15481 [==============================] - 555s 36ms/step - loss: 5.2831e-04 - acc: 0.9999\n",
            "Epoch 20/20\n",
            "15481/15481 [==============================] - 557s 36ms/step - loss: 5.2112e-04 - acc: 0.9998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ffa44f73f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5U-wVi-MUPd",
        "colab_type": "code",
        "outputId": "af3d61a6-d4ad-41bb-9692-0c8a89f377a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Evaluación del modelo\n",
        "test_loss, test_acc = model_2.evaluate(np_images_test, labels_categorical_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14726/14726 [==============================] - 3s 186us/step\n",
            "Test loss: 1.3624938972568712\n",
            "Test accuracy: 0.7546516365611843\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}